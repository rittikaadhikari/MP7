{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Webscraping using Python\n",
    "This scrapes Forever21's website to access the category name, display name, whether\n",
    "it is a final sale, the product id, and the list price of some dresses, tops, and bottoms.\n",
    "Then, it takes this information and converts it to a csv using pandas.\n",
    "\n",
    "Then, we experiment with Machine Learning packages (such as sklearn) to build a classifier\n",
    "that predicts what kind of category (dress, top, or bottom) a certain item should be, \n",
    "based on whether its a final sale, its product ID, and its listed price.\n",
    "\n",
    "rittika2\n",
    "sohams2\n",
    "'''\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "\n",
    "# returns the json containing information about clothes in seed url\n",
    "def get_clothes_json(seed_url):\n",
    "    # gets the html document for the seed url\n",
    "    html_doc = requests.get(seed_url).text\n",
    "    soup = BeautifulSoup(html_doc, \"html5lib\")\n",
    "    \n",
    "    # finds everything in the script tag\n",
    "    json_file = soup.find_all('script')\n",
    "    \n",
    "    # finds the \"correct\" script tag with the json about the clothes\n",
    "    save_json = \"\"\n",
    "    for json in json_file:\n",
    "        if (json.string != None):\n",
    "            if ('Loading Category' in json.string):\n",
    "                save_json = json.string\n",
    "\n",
    "    # gets the json inside the script tag\n",
    "    jsonValue = '{%s}' % (save_json.split('{', 1)[1].rsplit('}', 1)[0],)\n",
    "    jsonValue = re.split('[$]', jsonValue)[0]\n",
    "    return jsonValue\n",
    "\n",
    "# probably could have used a separate method to generate the seed_urls for the above function...\n",
    "# get jsons for dresses\n",
    "dress_1_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress')\n",
    "dress_2_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=2&pageSize=120&filter=price:0,250')\n",
    "dress_3_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=3&pageSize=120&filter=price:0,250')\n",
    "dress_4_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=4&pageSize=120&filter=price:0,250')\n",
    "dress_5_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=5&pageSize=120&filter=price:0,250')\n",
    "\n",
    "# get jsons for tops\n",
    "tops_1_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses')\n",
    "tops_2_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=2&pageSize=120&filter=price:0,250')\n",
    "tops_3_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=3&pageSize=120&filter=price:0,250')\n",
    "tops_4_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=4&pageSize=120&filter=price:0,250')\n",
    "tops_5_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=5&pageSize=120&filter=price:0,250')\n",
    "\n",
    "# get jsons for bottoms\n",
    "bottoms_1_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms')\n",
    "bottoms_2_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=2&pageSize=120&filter=price:0,250')\n",
    "bottoms_3_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=3&pageSize=120&filter=price:0,250')\n",
    "bottoms_4_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=4&pageSize=120&filter=price:0,250')\n",
    "bottoms_5_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=5&pageSize=120&filter=price:0,250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# converts a given json file to a pandas dataframe\n",
    "def convert_to_df(json_file):\n",
    "    \n",
    "    # splits the json file to help parse the json string\n",
    "    json_file = re.split(\"[:,]\", json_file)\n",
    "    \n",
    "    # lists of the attributes to be tracked\n",
    "    currIdx = 0\n",
    "    category_names = list()\n",
    "    display_names = list()\n",
    "    final_sales = list()\n",
    "    product_id = list()\n",
    "    list_prices = list()\n",
    "    \n",
    "    # iterates through the json string to find the attributes\n",
    "    # appends the list if the next element is not empty\n",
    "    for word in json_file:\n",
    "        if '\"CategoryName\"' == word:\n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                category_names.append(json_file[currIdx+1])\n",
    "        if '\"DisplayName\"' == word: \n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                display_names.append(json_file[currIdx+1])\n",
    "        if '\"FinalSale\"' == word:\n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                final_sales.append(json_file[currIdx+1])\n",
    "        if '\"ProductId\"' == word:\n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                product_id.append(json_file[currIdx+1])\n",
    "        if '\"ListPrice\"' == word: \n",
    "            # a hacky fix to avoid double/triple counting the list price... \n",
    "            if \"AM\" in json_file[currIdx-1] or \"PM\" in json_file[currIdx-1]:\n",
    "                list_prices.append(json_file[currIdx+1])\n",
    "        currIdx+=1\n",
    "        \n",
    "    # a hacky fix to even out the # of categories\n",
    "    del category_names[0]\n",
    "    \n",
    "    # creating proper generic labels for categories\n",
    "    if '\"bottoms\"' in category_names:\n",
    "        category_names = ['\"bottoms\"' for x in category_names]\n",
    "    if '\"top_blouses\"' in category_names:\n",
    "        category_names = ['\"tops\"' for x in category_names]\n",
    "    if '\"dress\"' in category_names:\n",
    "        category_names = ['\"dress\"' for x in category_names]\n",
    "    \n",
    "    \n",
    "    # data preprocessing: creating rows from the lists created above\n",
    "    rows = list()\n",
    "    for i in range(len(category_names)):\n",
    "        row = [category_names[i].strip('\"'), display_names[i].strip('\"'), final_sales[i].strip('\"'), \n",
    "               product_id[i].strip('\"'), list_prices[i].strip('\"')]\n",
    "        rows.append(row)  \n",
    "    \n",
    "    # creating a pandas dataframe from the rows\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # adding headers to dataframe\n",
    "    df.columns = [\"Category Name\", \"Display Name\", \"Final Sale\", \"Product ID\", \"List Price\"]\n",
    "    return df\n",
    "\n",
    "# converting the dress jsons to a pandas df\n",
    "df_dress_1 = convert_to_df(dress_1_json)\n",
    "df_dress_2 = convert_to_df(dress_2_json)\n",
    "df_dress_3 = convert_to_df(dress_3_json)\n",
    "df_dress_4 = convert_to_df(dress_4_json)\n",
    "df_dress_5 = convert_to_df(dress_5_json)\n",
    "\n",
    "# converting the tops jsons to a pandas df\n",
    "df_tops_1 = convert_to_df(tops_1_json)\n",
    "df_tops_2 = convert_to_df(tops_2_json)\n",
    "df_tops_3 = convert_to_df(tops_3_json)\n",
    "df_tops_4 = convert_to_df(tops_4_json)\n",
    "df_tops_5 = convert_to_df(tops_5_json)\n",
    "\n",
    "# converting the bottoms jsons to a pandas df\n",
    "df_bottoms_1 = convert_to_df(bottoms_1_json)\n",
    "df_bottoms_2 = convert_to_df(bottoms_2_json)\n",
    "df_bottoms_3 = convert_to_df(bottoms_3_json)\n",
    "df_bottoms_4 = convert_to_df(bottoms_4_json)\n",
    "df_bottoms_5 = convert_to_df(bottoms_5_json)\n",
    "\n",
    "# creating a list of dataframes\n",
    "df_list = [df_dress_1, df_dress_2, df_dress_3, df_dress_4, df_dress_5,\n",
    "          df_tops_1, df_tops_2, df_tops_3, df_tops_4, df_tops_5,\n",
    "          df_bottoms_1, df_bottoms_2, df_bottoms_3, df_bottoms_4, df_bottoms_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converts a list of pandas dataframes to a csv\n",
    "# and writes out the file to a given outfile\n",
    "def convert_to_csv(df_list, outfile):\n",
    "    # concatenates all of the dataframes\n",
    "    result = pd.concat(df_list)\n",
    "    \n",
    "    # converts the result to a csv\n",
    "    result.to_csv(outfile, index=False)\n",
    "\n",
    "convert_to_csv(df_list, 'out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy:  0.938095238095\n",
      "Test Accuracy:  0.885185185185\n",
      "Confusion Matrix on Training Data:\n",
      " [[400  13  17]\n",
      " [ 16 391  14]\n",
      " [  5  13 391]]\n",
      "Confusion Matrix on Test Data:\n",
      " [[145  12  13]\n",
      " [  9 154  16]\n",
      " [  5   7 179]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# This section uses a RandomForestClassifier (from sklearn) to \"classify\" the test data \n",
    "# (which we got from splitting the training data) into top, bottoms, and dress.\n",
    "# Then, it prints the RandomForestClassifier's accuracy on the training data and test data, \n",
    "# and prints out a confusion matrix. \n",
    " \n",
    "# data pre-processing\n",
    "df = pd.read_csv(\n",
    "    filepath_or_buffer='out', \n",
    "    header=None, \n",
    "    sep=',')\n",
    "\n",
    "headers = list(df.iloc[0])\n",
    "df.columns = headers\n",
    "df = df[1:]\n",
    "del df['Display Name']\n",
    "del headers[1]\n",
    "\n",
    "\n",
    "# preprocessing categorical data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "enc = LabelEncoder()\n",
    "df[headers[0]] = enc.fit_transform(df[headers[0]])\n",
    "df[headers[1]] = enc.fit_transform(df[headers[1]])\n",
    "\n",
    "# splitting training data\n",
    "train_x, test_x, train_y, test_y = train_test_split(df[headers[1:len(headers)]], df[headers[0]], \n",
    "                                                    train_size=0.70, test_size=0.30)\n",
    "\n",
    "# training random forest classifier\n",
    "clf = RandomForestClassifier(n_estimators = 1)\n",
    "clf.fit(train_x, train_y)\n",
    "\n",
    "\n",
    "# computing accuracies and confusion matrix\n",
    "print(\"Train Accuracy: \", accuracy_score(train_y, clf.predict(train_x), normalize=False)/len(train_y))\n",
    "print(\"Test Accuracy: \", accuracy_score(test_y, clf.predict(test_x), normalize=False)/len(test_y))\n",
    "print(\"Confusion Matrix on Training Data:\\n\", confusion_matrix(train_y, clf.predict(train_x)))\n",
    "print(\"Confusion Matrix on Test Data:\\n\", confusion_matrix(test_y, clf.predict(test_x)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
