{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Webscraping using Python\n",
    "This scrapes Forever21's website to access the category name, display name, whether\n",
    "it is a final sale, the product id, and the list price of some dresses, tops, and bottoms.\n",
    "Then, it takes this information and converts it to a csv using pandas.\n",
    "\n",
    "rittika2\n",
    "sohams2\n",
    "'''\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re\n",
    "\n",
    "# returns the json containing information about clothes in seed url\n",
    "def get_clothes_json(seed_url):\n",
    "    # gets the html document for the seed url\n",
    "    html_doc = requests.get(seed_url).text\n",
    "    soup = BeautifulSoup(html_doc, \"html5lib\")\n",
    "    \n",
    "    # finds everything in the script tag\n",
    "    json_file = soup.find_all('script')\n",
    "    \n",
    "    # finds the \"correct\" script tag with the json about the clothes\n",
    "    save_json = \"\"\n",
    "    for json in json_file:\n",
    "        if (json.string != None):\n",
    "            if ('Loading Category' in json.string):\n",
    "                save_json = json.string\n",
    "\n",
    "    # gets the json inside the script tag\n",
    "    jsonValue = '{%s}' % (save_json.split('{', 1)[1].rsplit('}', 1)[0],)\n",
    "    jsonValue = re.split('[$]', jsonValue)[0]\n",
    "    return jsonValue\n",
    "\n",
    "# probably could have used a separate method to generate the seed_urls for the above function...\n",
    "# get jsons for dresses\n",
    "dress_1_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress')\n",
    "dress_2_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=2&pageSize=120&filter=price:0,250')\n",
    "dress_3_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=3&pageSize=120&filter=price:0,250')\n",
    "dress_4_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=4&pageSize=120&filter=price:0,250')\n",
    "dress_5_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/dress#pageno=5&pageSize=120&filter=price:0,250')\n",
    "\n",
    "# get jsons for tops\n",
    "tops_1_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses')\n",
    "tops_2_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=2&pageSize=120&filter=price:0,250')\n",
    "tops_3_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=3&pageSize=120&filter=price:0,250')\n",
    "tops_4_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=4&pageSize=120&filter=price:0,250')\n",
    "tops_5_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/top_blouses#pageno=5&pageSize=120&filter=price:0,250')\n",
    "\n",
    "# get jsons for bottoms\n",
    "bottoms_1_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms')\n",
    "bottoms_2_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=2&pageSize=120&filter=price:0,250')\n",
    "bottoms_3_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=3&pageSize=120&filter=price:0,250')\n",
    "bottoms_4_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=4&pageSize=120&filter=price:0,250')\n",
    "bottoms_5_json = get_clothes_json('https://www.forever21.com/us/shop/Catalog/Category/f21/bottoms#pageno=5&pageSize=120&filter=price:0,250')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# converts a given json file to a pandas dataframe\n",
    "def convert_to_df(json_file):\n",
    "    \n",
    "    # splits the json file to help parse the json string\n",
    "    json_file = re.split(\"[:,]\", json_file)\n",
    "    \n",
    "    # lists of the attributes to be tracked\n",
    "    currIdx = 0\n",
    "    category_names = list()\n",
    "    display_names = list()\n",
    "    final_sales = list()\n",
    "    product_id = list()\n",
    "    list_prices = list()\n",
    "    \n",
    "    # iterates through the json string to find the attributes\n",
    "    # appends the list if the next element is not empty\n",
    "    for word in json_file:\n",
    "        if '\"CategoryName\"' == word:\n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                category_names.append(json_file[currIdx+1])\n",
    "        if '\"DisplayName\"' == word: \n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                display_names.append(json_file[currIdx+1])\n",
    "        if '\"FinalSale\"' == word:\n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                final_sales.append(json_file[currIdx+1])\n",
    "        if '\"ProductId\"' == word:\n",
    "            if not json_file[currIdx+1] == '\"\"':\n",
    "                product_id.append(json_file[currIdx+1])\n",
    "        if '\"ListPrice\"' == word: \n",
    "            # a hacky fix to avoid double/triple counting the list price... \n",
    "            if \"AM\" in json_file[currIdx-1] or \"PM\" in json_file[currIdx-1]:\n",
    "                list_prices.append(json_file[currIdx+1])\n",
    "        currIdx+=1\n",
    "        \n",
    "    # a hacky fix to even out the # of categories\n",
    "    del category_names[0]\n",
    "    \n",
    "    # data preprocessing: creating rows from the lists created above\n",
    "    rows = list()\n",
    "    for i in range(len(category_names)):\n",
    "        row = [category_names[i].strip('\"'), display_names[i].strip('\"'), final_sales[i].strip('\"'), \n",
    "               product_id[i].strip('\"'), list_prices[i].strip('\"')]\n",
    "        rows.append(row)  \n",
    "    \n",
    "    # creating a pandas dataframe from the rows\n",
    "    df = pd.DataFrame(rows)\n",
    "    \n",
    "    # adding headers to dataframe\n",
    "    df.columns = [\"Category Name\", \"Display Name\", \"Final Sale\", \"Product ID\", \"List Price\"]\n",
    "    return df\n",
    "\n",
    "# converting the dress jsons to a pandas df\n",
    "df_dress_1 = convert_to_df(dress_1_json)\n",
    "df_dress_2 = convert_to_df(dress_2_json)\n",
    "df_dress_3 = convert_to_df(dress_3_json)\n",
    "df_dress_4 = convert_to_df(dress_4_json)\n",
    "df_dress_5 = convert_to_df(dress_5_json)\n",
    "\n",
    "# converting the tops jsons to a pandas df\n",
    "df_tops_1 = convert_to_df(tops_1_json)\n",
    "df_tops_2 = convert_to_df(tops_2_json)\n",
    "df_tops_3 = convert_to_df(tops_3_json)\n",
    "df_tops_4 = convert_to_df(tops_4_json)\n",
    "df_tops_5 = convert_to_df(tops_5_json)\n",
    "\n",
    "# converting the bottoms jsons to a pandas df\n",
    "df_bottoms_1 = convert_to_df(bottoms_1_json)\n",
    "df_bottoms_2 = convert_to_df(bottoms_2_json)\n",
    "df_bottoms_3 = convert_to_df(bottoms_3_json)\n",
    "df_bottoms_4 = convert_to_df(bottoms_4_json)\n",
    "df_bottoms_5 = convert_to_df(bottoms_5_json)\n",
    "\n",
    "# creating a list of dataframes\n",
    "df_list = [df_dress_1, df_dress_2, df_dress_3, df_dress_4, df_dress_5,\n",
    "          df_tops_1, df_tops_2, df_tops_3, df_tops_4, df_tops_5,\n",
    "          df_bottoms_1, df_bottoms_2, df_bottoms_3, df_bottoms_4, df_bottoms_5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# converts a list of pandas dataframes to a csv\n",
    "# and writes out the file to a given outfile\n",
    "def convert_to_csv(df_list, outfile):\n",
    "    # concatenates all of the dataframes\n",
    "    result = pd.concat(df_list)\n",
    "    \n",
    "    # converts the result to a csv\n",
    "    result.to_csv(outfile, index=False)\n",
    "\n",
    "convert_to_csv(df_list, 'out')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
